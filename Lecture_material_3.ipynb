{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('titanic')\n",
    "df.rename(columns={\"sex\": \"gender\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['deck'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use loc function to select rows and columns by label\n",
    "df.loc[0:4,'age':'fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iloc function to select rows and columns by position\n",
    "df.iloc[0:4,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanti to excess from 0 to 4 rows then 8 to 12 rows and 0 to 4 columns using loc function\n",
    "df.loc[np.r_[0:4,8:12],['age','fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanti to excess from 0 to 4 rows then 8 to 12 rows and 0 to 4 columns\n",
    "df.iloc[np.r_[0:4,8:12],0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x='gender', y=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter quartile range method\n",
    "Q1=df['age'].quantile(0.25)\n",
    "Q3=df['age'].quantile(0.75) \n",
    "IQR=Q3-Q1\n",
    "lower_limit=Q1-1.5*IQR\n",
    "upper_limit=Q3+1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[(df['age']>lower_limit) & (df['age']<upper_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df['fare'].quantile(0.25)\n",
    "Q3=df['fare'].quantile(0.75) \n",
    "IQR=Q3-Q1\n",
    "lower_limit=Q1-1.5*IQR\n",
    "upper_limit=Q3+1.5*IQR\n",
    "df=df[(df['fare']>lower_limit) & (df['fare']<upper_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates=df[df.duplicated()]\n",
    "df_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "df[['age','fare']]=scaler.fit_transform(df[['age','fare']])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"family\"]=df['sibsp']+df['parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.swarmplot(data=df, x=\"gender\", y=\"family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=df, x=\"gender\", y=\"age\",hue='family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.pivot_table(df, values=\"fare\", index=\"pclass\", columns=\"survived\", aggfunc=np.sum)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Sample data\n",
    "data = {'numbers': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data using min max scalar\n",
    "scaler = MinMaxScaler()\n",
    "df['numbers_scaled'] = scaler.fit_transform(df[['numbers']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scalar or Z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data using standard scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['numbers_scaled'] = scaler.fit_transform(df[['numbers']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# Sample data with outliers\n",
    "\n",
    "# Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "df['numbers_scaled'] = scaler.fit_transform(df[['numbers']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logrithmic scaling/ Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#random data with outliers\n",
    "\n",
    "# Log Transform\n",
    "df['numbers_log'] = np.log(df['numbers'])\n",
    "df['numbers_log2'] = np.log2(df['numbers'])\n",
    "df['numbers_log10'] = np.log10(df['numbers'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# One-Hot Encoding\n",
    "encoded_data = pd.get_dummies(df, columns=['Color'])\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Sample data\n",
    "data = {'Animal': ['Dog', 'Cat', 'Bird', 'Dog', \"lion\"]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Animal_encoded'] = label_encoder.fit_transform(df['Animal'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Sample data\n",
    "data = {'Size': ['Small', 'Medium', 'Large', 'Medium']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Ordinal Encoding\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Small', 'Medium', 'Large']])\n",
    "df['Size_encoded'] = ordinal_encoder.fit_transform(df[['Size']])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
