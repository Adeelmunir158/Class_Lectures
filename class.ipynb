{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2024-04-05 09:22:52.007173\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.datetime.now()\n",
    "\n",
    "# Print the current date and time\n",
    "print(\"Timestamp:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipykernal\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "#pip install matplotlib  \n",
    "#pip install seaborn\n",
    "#pip install statsmodels\n",
    "# pip install scikit-learn\n",
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 1\n",
    "Use dataset of penguins to find the correlation between the columns and to draw the regression plot for each variable as well as heatmap and pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 2\n",
    "To perform exploratory data analysis using data of penguins to find different trends and patterns in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 3\n",
    "To perform the EDA on --------------- to find the different patterns and trends in the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Session 4\n",
    "Write compete detail of left join, right join, inner and outer join. Develop two dataframes of 15 rows with columns as\n",
    "data1= id, Name, nationality,age\\\n",
    "data2= id, Marks in math, marks in science, marks in english, marks in history\n",
    "and merge these dataframes using all types of joins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 5\n",
    "\n",
    "Using the dataset of titanic, check the normal distribution of all numeric columns and use power transformation and quantile transformation methods (Whichever approperiate) to convert these columns as parametric distribited columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 6\n",
    "Use the one hot encoding, ordinal encoding and label encoding to convert the categorical columns into encoded data using the data of tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 7\n",
    "1. Apply simple linear regression model using the data of \"IRIS\". Take sepal_width as attribute and sepal_length as target variable. Split the data into training and testing and find the accuracy of the model\n",
    "2. Apply multiple linear regression model using the data of \"IRIS\". Take sepal_width, petal_length, petal_width as attribute and sepal_length as target variable. Split the data into training and testing and find the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 8\n",
    "\n",
    "By using logistic regression and using the data of penguins, predict the species of penguins based on the columns culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g. Split the data into training and testing and find the accuracy of the model. Evaluate the model using confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 9\n",
    "\n",
    "By using SVC and using the data of penguins, predict the species of penguins based on the columns culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g. Split the data into training and testing and find the accuracy of the model. Evaluate the model using confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 10\n",
    "\n",
    "By using KNN and using the data of titanic, predict the survived columns based on the columns remaining columns. Split the data into training and testing and find the accuracy of the model. Evaluate the model using confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session 10\n",
    "\n",
    "By using Decision tree Regressor and using the data of tips, predict the tip columns based on the remaining columns. Split the data into training and testing and find the r2 of the model. Draw the tree diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach's alpha: (0.9146132562429197, array([0.846, 0.962]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pingouin import reliability\n",
    "responses_df1 = pd.read_csv('Employer_Survey.CSV')\n",
    "# Calculate Cronbach's alpha\n",
    "alpha = reliability.cronbach_alpha(data=responses_df1)\n",
    "print(\"Cronbach's alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach's alpha: (0.8376586191455032, array([0.776, 0.889]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pingouin import reliability\n",
    "responses_df2 = pd.read_csv('Alumni_Survey.CSV')\n",
    "# Calculate Cronbach's alpha\n",
    "alpha = reliability.cronbach_alpha(data=responses_df2)\n",
    "print(\"Cronbach's alpha:\", alpha)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
